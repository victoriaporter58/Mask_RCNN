{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN Classifier.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victoriaporter58/Mask_RCNN/blob/master/KNN_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z89StCmHTFH6",
        "colab_type": "text"
      },
      "source": [
        "#K-Nearest Neighbours Classification\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1WtALvyPsTTSHpsgfZ_SH8fat2WwKIMQk#scrollTo=Z89StCmHTFH6)\n",
        "\n",
        "The KNN algorithm is simple and versatile. It assumes that similar things exist in close proximity. The objective here is to find the parameter set-up that provides the most time efficient and accuracte analysis of the MNIST dataset. To do this, the following parameters are being considered:\n",
        "\n",
        "\n",
        "*   ***n_neighbours***: The number of neighbours to use.\n",
        "*   ***weights***: The weight function used in prediction (uniform or distance.)\n",
        "*   ***algorithm***: The algorithm used to calculate the nearest neighbours (ball_tree, kd_tree or brute.)\n",
        "*   ***leaf size***: Leaf size passed to BallTree or KDTree.\n",
        "\n",
        "**References**:\n",
        "https://www.codingame.com/playgrounds/37409/handwritten-digit-recognition-using-scikit-learn, https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9CrkKEzSOcp",
        "colab_type": "text"
      },
      "source": [
        "##Downgrade Tensorflow\n",
        "We need to downgrade tensorflow so that we can use it to import the MNIST dataset. Restart the runtime after executing this cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjC5VtIOGAUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorflow==1.14"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMTz7mXSUSrB",
        "colab_type": "text"
      },
      "source": [
        "##Import the required libraries and the MNIST dataset\n",
        "We prepare the dataset by splitting it into training images, training labels, testing images and testing labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ9fxUPwUqet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# import and read the MNIST dataset\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('/home/server/datasets/MNIST_data/')\n",
        "\n",
        "# set-up dataset as numpy array\n",
        "# seperate the dataset into training (60,000) images & labels and testing (10,000) images & labels\n",
        "train_images = np.asarray(mnist.train.images)\n",
        "train_labels = np.asarray(mnist.train.labels)\n",
        "test_images = np.asarray(mnist.test.images)\n",
        "test_labels = np.asarray(mnist.test.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBycV9EEV--e",
        "colab_type": "text"
      },
      "source": [
        "##Fine-tune parameters\n",
        "We want to identify the optimal k value, weights, algorithm and leaf size for the MNIST dataset.\n",
        "\n",
        "**NOTE**: The cell below is time consuming to execute and is only used to find the optimal parameters. **Skip this cell and execute the next one to train the final model**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhHDmCdzV3y-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "b57389ad-f982-4c44-9d09-459fa41a3b52"
      },
      "source": [
        "# record the expected results for comparison with predictions\n",
        "expected = test_labels.tolist()\n",
        "\n",
        "# initialise the range of k values we are using i.e. all odd numbers (to prevent ties) between 1 and 30 inclusive\n",
        "# we want to identify what k value produces the most accurate results before we handle predictions\n",
        "# accuracies will record the score of each k value i.e. how many predictions the k-nn classifier got correct\n",
        "kVals = range(1, 30, 2)\n",
        "accuracies = []\n",
        "weights = 'distance' # or 'uniform' but using distance improved the accuracy\n",
        "algorithm = 'brute' # or 'kd_tree' or 'ball_tree' however brute was the most time efficient and maintained a high accuracy\n",
        "\n",
        "print(\"Executing...\")\n",
        "\n",
        "# loop over the k values we have chosen\n",
        "for k in range(1, 30, 2):\n",
        "\t# train the classifier using the current k value\n",
        "\tmodel = KNeighborsClassifier(weights=weights,n_neighbors=k, algorithm=algorithm)\n",
        "\tmodel.fit(train_images, train_labels)\n",
        " \n",
        "\t# check how many predictions the classifer got correct and update the accuracies list\n",
        "\tscore = model.score(test_images, expected)\n",
        "\tprint(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
        "\taccuracies.append(score)\n",
        " \n",
        "# find the value of k that has the highest accuracy - this is the k value that we will use\n",
        "highest_accuracy_value = int(np.argmax(accuracies))\n",
        "# print the parameter set-up\n",
        "print(f\"Weights = {weights}\")\n",
        "print(f\"Algorithm = {algorithm}\")\n",
        "print(\"k=%d achieved highest accuracy of %.2f%% on testing data\" % (kVals[highest_accuracy_value], accuracies[highest_accuracy_value] * 100))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing...\n",
            "k=1, accuracy=96.77%\n",
            "k=3, accuracy=97.09%\n",
            "k=5, accuracy=96.86%\n",
            "k=7, accuracy=96.84%\n",
            "k=9, accuracy=96.75%\n",
            "k=11, accuracy=96.64%\n",
            "k=13, accuracy=96.47%\n",
            "k=15, accuracy=96.39%\n",
            "k=17, accuracy=96.40%\n",
            "k=19, accuracy=96.31%\n",
            "k=21, accuracy=96.23%\n",
            "k=23, accuracy=96.11%\n",
            "k=25, accuracy=96.07%\n",
            "k=27, accuracy=95.99%\n",
            "k=29, accuracy=95.91%\n",
            "Weights = distance\n",
            "Algorithm = brute\n",
            "k=3 achieved highest accuracy of 97.09% on testing data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjiH9WKkdyaj",
        "colab_type": "text"
      },
      "source": [
        "##Train using the optimal K value\n",
        "The above cell is time consuming to execute, so based on our tests, the optimal parameters for the MNIST dataset are:\n",
        "* k = 3\n",
        "* weights = 'uniform'\n",
        "* algorithm = 'brute'\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_pA4h21d0kJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up the model using the k value we found above with the highest accuracy\n",
        "model = KNeighborsClassifier(weights='distance',n_neighbors=3,algorithm='brute')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvfzaymLj3Ww",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7d911c65-2944-400e-bc51-907031be3527"
      },
      "source": [
        "# train the model\n",
        "model.fit(train_images, train_labels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
              "                     weights='distance')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVq0Q1cKafGo",
        "colab_type": "text"
      },
      "source": [
        "##Predictions\n",
        "Now that the model has been trained, we want to make predictions on the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1DKrcFjeJpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(test_images)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsMqlCRja4dD",
        "colab_type": "text"
      },
      "source": [
        "##Evaluation\n",
        "Now that we have predictions, we want to visualise them.\n",
        "* ***Accuracy***: The accuracy of our classifier.\n",
        "* ***Classification report***: This shows us how accurate our classifier is at identifying each class.\n",
        "* ***Confusion matrix***: This shows us exactly how many samples our classifier got correct/incorrect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg-MOlJYj5sk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "c276e9b8-caae-4066-8689-23d2a7f4c01c"
      },
      "source": [
        "# print a classification report to show how the classifer performed on each digit\n",
        "print(\"Accuracy: \", accuracy_score(expected, predictions), \"\\n\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(expected, predictions), \"\\n\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(expected, predictions))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.9709 \n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       980\n",
            "           1       0.97      1.00      0.98      1135\n",
            "           2       0.99      0.97      0.98      1032\n",
            "           3       0.97      0.96      0.97      1010\n",
            "           4       0.97      0.97      0.97       982\n",
            "           5       0.96      0.97      0.96       892\n",
            "           6       0.98      0.99      0.98       958\n",
            "           7       0.96      0.97      0.96      1028\n",
            "           8       0.99      0.94      0.96       974\n",
            "           9       0.96      0.96      0.96      1009\n",
            "\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.97      0.97      0.97     10000\n",
            "weighted avg       0.97      0.97      0.97     10000\n",
            " \n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 974    1    1    0    0    1    2    1    0    0]\n",
            " [   0 1132    2    0    1    0    0    0    0    0]\n",
            " [   9    5  997    2    0    0    1   16    2    0]\n",
            " [   0    1    4  973    1   14    1    7    5    4]\n",
            " [   0    6    0    0  948    0    5    4    1   18]\n",
            " [   4    1    0   10    2  862    5    1    2    5]\n",
            " [   4    3    0    0    4    3  944    0    0    0]\n",
            " [   0   18    3    0    4    0    0  993    0   10]\n",
            " [   6    0    3   14    5   14    3    4  919    6]\n",
            " [   3    4    2    7    9    4    1   10    2  967]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35XAKw-EDhBb",
        "colab_type": "text"
      },
      "source": [
        "#Testing\n",
        "This code allows us to choose an image from the testing dataset and allow our classifier to make a prediction on it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMjFBKRuDf_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "062bfc2a-442e-437a-e8fd-bf6c35eb4503"
      },
      "source": [
        "# select image index from test dataset\n",
        "image_index = 4444\n",
        "\n",
        "# reshape the test image so that it fits on screen\n",
        "# make colourmap greyscale\n",
        "plt.imshow(test_images[image_index].reshape(28, 28),cmap='Greys')\n",
        "\n",
        "# make a prediction on the image using the classifier defined and trained above\n",
        "# (1,-1) means we are using a single sample\n",
        "pred = model.predict(test_images[image_index].reshape(1,-1))[0]\n",
        "\n",
        "# print the classifier's prediction\n",
        "print(\"Prediction: \",pred)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction:  9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}